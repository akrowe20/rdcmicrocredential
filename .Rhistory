plot(cars)
install.packages ("devtools")
install.packages ("devtools")
library("devtools")
devtools::insstall_github("benjjneb/dada2", ref="v1.16")
install.packages("devtools")
library(dada2); packageVerson("dada2")
devtools::install_github("benjjneb/dada2", ref="v1.16") # change the ref argument to get other versions
devtools::install_github("benjjneb/dada2", ref="v1.16") # change the ref argument to get other versions
library(dada2); packageVerson("dada2")
library(dada2)
BiocManager::install(version = "3.11")
if (!requireNamespace("BiocManager", quietly = TRUE))
install.packages("BiocManager")
BiocManager::install(version = "3.11")
if (!requireNamespace("BiocManager", quietly = TRUE))
install.packages("BiocManager")
BiocManager::install("dada2", version = "3.11")
install.packages(“BiocManager”)
install.packages(“BiocManager”)
install.packages("BiocManager")
BiocManager::install("phyloseq")
install.packages("BiocManager")
BiocManager::install("dada2")
install.packages("BiocManager")
BiocManager::install("dada2")
Install.packages("BiocManager")
install.packages("BiocManager")
BiocManager::("dada2")
BiocManager::install("dada2")
install.packages(“BiocManager”)
install.packages("BiocManager")
BiocManager::install("dada2")
localDir="."
dataDir= file.path(localDir, "data")
ModelDir = file.path(localDir, "models")
MixingDir = file.path(localDir, "mixing")
MFDir = file.path9localDir, "model_fit")
source("load_libraries.r")
library(knitr)
localDir="."
dataDir= file.path(localDir, "data")
ModelDir = file.path(localDir, "models")
MixingDir = file.path(localDir, "mixing")
MFDir = file.path9localDir, "model_fit")
source("load_libraries.r")
MFDir = file.path(localDir, "model_fit")
source("load_libraries.r")
library(knitr)
data = read.csv(file.path(dataDir, "data.csv"))
localDir = "."
dataDir = file.path(localDir, "data") ModelDir = file.path(localDir, "models") MixingDir = file.path(localDir, "mixing") MFDir = file.path(localDir, "model_fit") source("load_libraries.r")
library(knitr)
localDir = "."
dataDir = file.path(localDir, "data") ModelDir = file.path(localDir, "models") MixingDir = file.path(localDir, "mixing") MFDir = file.path(localDir, "model_fit") source("load_libraries.r")
library(knitr)
localDir = "."
dataDir = file.path(localDir, "data") ModelDir = file.path(localDir, "models") MixingDir = file.path(localDir, "mixing") MFDir = file.path(localDir, "model_fit") source("load_libraries.r")
library(knitr)
localDir = "."
dataDir = file.path(localDir, "data")
ModelDir = file.path(localDir, "models")
MixingDir = file.path(localDir, "mixing")
MFDir = file.path(localDir, "model_fit")
source("load_libraries.r")
library(knitr)
source("load_libraries.r")
data = read.csv(file.path(dataDir, "data.csv"))
library(Hmsc)
install.packages(Hmsc)
install.packages("Hmsc")
library(Hmsc)
install.packages("Hmsc 2")
install.packages("Hmsc 3")
install.packages("Hmsc 4")
install.packages("Hmsc 5")
install.packages("Hmsc 6")
library(Hmsc)
library(knitr)
source("load_libraries.r")
install.packages("Hmsc 2")
install.packages("Hmsc 3")
install.packages("Hmsc 4")
install.packages("Hmsc 5")
install.packages("Hmsc 6")
install.packages("devtools") # if not yet installed
library(Hmsc )
install.packages("devtools")
library("devtools")
library("Hmsc")
install_github("hmsc-r/HMSC")
library(Hmsc)
library("Hmsc")
install.packages("devtools")
library(devtools)
install_github("hmsc-r/HMSC")
library("Hmsc")
library(Hmsc)
set.seed(1)
n= 50
x = rnorm(n)
alpha = 0
beta = 1
L = alpha +beta*x
y = L _rnorm(n, sd = sigma)
plot(x,y, las=1)
y = L + rnorm (n, sd = sigma)
n = 50
x = rnorm(n)
alpha = 0
beta = 1
sigma = 1
L = alpha + beta*x
y = L + rnorm(n, sd = sigma)
plot(x, y, las=1)
df = data.frame(x,y)
m.lm = lm( y ~ x, data=df)
summary(m.lm)
Y= as.matrix (y)
XData = data.fram (x = x)
XData = data.frame (x = x)
m = Hmsc( Y = Y, XData = XData, XFormula =~x)
nChains = 2
test.run = TRUE
if (test.run) {
thin = 1
samples = 10
transient = 5
verbose = 5
} else {
thin = 5
samples = 100
transient = 500*thin
verbose = 500*thin
}
m = sampleMcmc(m, thin = thin, samples = samples, transient = transient, nchains = nChains, verbose = verbose)
m = sampleMcmc(m, thin = thin, samples = samples, transient = transient, nChains = nChains, verbose = verbose)
mpost = convertToCodaObject(m)
summary(mpost$Beta)
preds = computePredictedValues(m)
evaluateModelFit(hM=m, predY=preds)
n=200
a
install.packages("Hmsc")
install.packages("rgee")
rgee::ee_install()
rgee::ee_check()
library(rgee)
ee_Initialize()
4/1AanRRrvafNLZksqQrrvo_IcZ4GmZzhYbC_ynJ4o-ReILHNkikeUNYIuZ7uU
ee)Authenticate()
ee_Authenticate()
4/1AanRRrvT5uQsG2pBpm-Nj2mcZdl1YRi4QxWXMtfwLvPJ4s8aJ7Ql-hblCEc
globcover <- ee$Image("ESA/GLOBCOVER_L4_200901_200912_V2_3")
ee_Initialize()
ee_Initialize()
ee_Authenticate()
4/1AanRRrtp0tIxbRlEm81ABJbbpDm77uPGe88TRymfcmz7lnWpThKJnb0Br7U
ee_Initialize()
ee_clean_user_credentials()
ee_Initialize()
4/1AanRRrsFZRa-BHTRZSjW6mBUyJWSA0Md_ln0kvy6can77wuVnI6xwwqYnB4
globcover <- ee$Image("ESA/GLOBCOVER_L4_200901_200912_V2_3")
ee_Authenticate()
4/1AanRRrsd_QToUKFBoFNnip_8-Y3Bxv_LAIsKQkOsAUcRxoStsf04b9mAIVs
globcover <- ee$Image("ESA/GLOBCOVER_L4_200901_200912_V2_3")
ee_Initialize()
ee_clean_pyenv()
#Next, I need to download the dataset as a GeoTiff file from the ESA GlobCoverLink and use terra to load the data in R
library(terra)
#Next, I need to download the dataset as a GeoTiff file from the ESA GlobCoverLink and use terra to load the data in R
library(terra)
library (landscapemetrics)
library(rgee)
ee_clean_user_credentials()
ee_Initialize()
library(reticulate)
use_python("/opt/anaconda3/bin/python", required = TRUE)
rgee::ee_install()
ee_clean_pyenv()
rgee::ee_install()
ee_clean_pyenv()
setwd("~/Dropbox/CU Postdoc/Resources, Workshops, Tutorials/Data Foundations Camp/FinalProject/GitHub/rdcmicrocredential")
# Load administrative boundaries (FAO GAUL Level 1)
regions <- ee$FeatureCollection("FAO/GAUL_SIMPLIFIED_500m/2015/level1")
#Example for just Madagascar
library(rgee)
ee_Initialize()
# Load dataset
globcover <- ee$Image("ESA/GLOBCOVER_L4_200901_200912_V2_3")
# Define ROI (Example: Madagascar region)
roi <- ee$Geometry$Rectangle(c(45, -20, 50, -15))
# Resample the dataset to 1 km resolution
resampled_globcover <- globcover$reduceResolution(
reducer = ee$Reducer$mode(),
maxPixels = 1024
)$reproject(
crs = globcover$projection(),
scale = 1000
)
# Calculate land cover percentages
landcover_stats <- resampled_globcover$reduceRegion(
reducer = ee$Reducer$frequencyHistogram(),
geometry = roi,
scale = 1000,
maxPixels = 1e13
)
# Fetch and print results
landcover_percentages <- ee$Dictionary(landcover_stats)$getInfo()
print(landcover_percentages)
# Load administrative boundaries (FAO GAUL Level 1)
regions <- ee$FeatureCollection("FAO/GAUL_SIMPLIFIED_500m/2015/level1")
# Resample GlobCover to a coarser resolution (e.g., 10 km)
resampled_globcover <- globcover$reduceResolution(
reducer = ee$Reducer$mode(),  # Use mode for categorical data
maxPixels = 1024
)$reproject(
crs = globcover$projection(),
scale = 10000  # 10 km resolution
)
# Compute zonal statistics (percentage of each land cover type per region)
zonal_stats <- resampled_globcover$reduceRegions(
collection = regions,
reducer = ee$Reducer$frequencyHistogram(),  # Histogram for categorical data
scale = 10000  # Match resampled resolution
)
# Inspect the results
zonal_stats_info <- zonal_stats$getInfo()
print(landcover_percentages)
print(zonal_stats_info)
# Compute zonal statistics (percentage of each land cover type per region)
zonal_stats <- resampled_globcover$reduceRegions(
collection = regions,
reducer = ee$Reducer$frequencyHistogram(),  # Histogram for categorical data
scale = 10000  # Match resampled resolution
)
# Inspect the results
zonal_stats_info <- zonal_stats$getInfo()
# Resample GlobCover to a coarser resolution (e.g., 10 km)
resampled_globcover <- globcover$reduceResolution(
reducer = ee$Reducer$mode(),  # Use mode for categorical data
maxPixels = 1e13
)$reproject(
crs = globcover$projection(),
scale = 10000  # 10 km resolution
)
# Compute zonal statistics (percentage of each land cover type per region)
zonal_stats <- resampled_globcover$reduceRegions(
collection = regions,
reducer = ee$Reducer$frequencyHistogram(),  # Histogram for categorical data
scale = 10000  # Match resampled resolution
)
# Inspect the results
zonal_stats_info <- zonal_stats$getInfo()
# Load administrative boundaries (FAO GAUL Level 1)
regions <- ee$FeatureCollection("FAO/GAUL_SIMPLIFIED_500m/2015/level1")
# Resample GlobCover to a coarser resolution (e.g., 10 km)
resampled_globcover <- globcover$reduceResolution(
reducer = ee$Reducer$mode(),  # Use mode for categorical data
maxPixels = 1024
)$reproject(
crs = globcover$projection(),
scale = 10000  # 10 km resolution
)
# Resample GlobCover to a coarser resolution (e.g., 10 km)
resampled_globcover <- globcover$reduceResolution(
reducer = ee$Reducer$mode(),  # Use mode for categorical data
maxPixels = 1024
)$reproject(
crs = globcover$projection(),
scale = 20000  # 10 km resolution
)
# Compute zonal statistics (percentage of each land cover type per region)
zonal_stats <- resampled_globcover$reduceRegions(
collection = regions,
reducer = ee$Reducer$frequencyHistogram(),  # Histogram for categorical data
scale = 20000  # Match resampled resolution
)
# Inspect the results
zonal_stats_info <- zonal_stats$getInfo()
# Resample GlobCover to a coarser resolution (e.g., 10 km)
resampled_globcover <- globcover$reduceResolution(
reducer = ee$Reducer$mode(),  # Use mode for categorical data
maxPixels = 1024
)$reproject(
crs = globcover$projection(),
scale = 10000 # 10 km resolution
)
# Compute zonal statistics (percentage of each land cover type per region)
zonal_stats <- resampled_globcover$reduceRegions(
collection = regions,
reducer = ee$Reducer$frequencyHistogram(),  # Histogram for categorical data
scale = 10000  # Match resampled resolution
maxPixels = 1e13
# Resample GlobCover to a coarser resolution (e.g., 10 km)
resampled_globcover <- globcover$reduceResolution(
reducer = ee$Reducer$mode(),  # Use mode for categorical data
maxPixels = 1024
)$reproject(
crs = globcover$projection(),
scale = 10000  # 10 km resolution
)
# Compute zonal statistics (percentage of each land cover type per region)
zonal_stats <- resampled_globcover$reduceRegions(
collection = regions,
reducer = ee$Reducer$frequencyHistogram(),  # Histogram for categorical data
scale = 10000
maxPizels = 1e13# Match resampled resolution
# Compute zonal statistics (percentage of each land cover type per region)
zonal_stats <- resampled_globcover$reduceRegions(
collection = regions,
reducer = ee$Reducer$frequencyHistogram(),  # Histogram for categorical data
scale = 10000
maxPixels = 1e13. # Match resampled resolution
# Compute zonal statistics (percentage of each land cover type per region)
zonal_stats <- resampled_globcover$reduceRegions(
collection = regions,
reducer = ee$Reducer$frequencyHistogram(),  # Histogram for categorical data
scale = 10000
maxPixels = 1e13 # Match resampled resolution
ee_Initialize()
# Load dataset
globcover <- ee$Image("ESA/GLOBCOVER_L4_200901_200912_V2_3")
# Load administrative boundaries (FAO GAUL Level 1)
regions <- ee$FeatureCollection("FAO/GAUL_SIMPLIFIED_500m/2015/level1")
# Resample GlobCover to a coarser resolution (e.g., 10 km)
resampled_globcover <- globcover$reduceResolution(
reducer = ee$Reducer$mode(),  # Use mode for categorical data
maxPixels = 1024
)$reproject(
crs = globcover$projection(),
scale = 10000  # 10 km resolution
)
# Compute zonal statistics (percentage of each land cover type per region)
zonal_stats <- resampled_globcover$reduceRegions(
collection = regions,
reducer = ee$Reducer$frequencyHistogram(),  # Histogram for categorical data
scale = 10000
maxPixels = 1e13 # Match resampled resolution
# Compute zonal statistics (percentage of each land cover type per region)
zonal_stats <- resampled_globcover$reduceRegions(
collection = regions,
reducer = ee$Reducer$frequencyHistogram(),  # Histogram for categorical data
scale = 10000,
maxPixels = 1e13 # Match resampled resolution
)
# Resample GlobCover to a coarser resolution (e.g., 10 km)
resampled_globcover <- globcover$reduceResolution(
reducer = ee$Reducer$mode(),  # Use mode for categorical data
maxPixels = 1024
)$reproject(
crs = globcover$projection(),
scale = 20000  # 10 km resolution
)
# Compute zonal statistics (percentage of each land cover type per region)
zonal_stats <- resampled_globcover$reduceRegions(
collection = regions,
reducer = ee$Reducer$frequencyHistogram(),  # Histogram for categorical data
scale = 10000,
# Match resampled resolution
)
# Inspect the results
zonal_stats_info <- zonal_stats$getInfo()
# Resample GlobCover to a coarser resolution (e.g., 10 km)
resampled_globcover <- globcover$reduceResolution(
reducer = ee$Reducer$mode(),  # Use mode for categorical data
maxPixels = 1024
)$reproject(
crs = globcover$projection(),
scale = 10000  # 10 km resolution
)
# Compute zonal statistics (percentage of each land cover type per region)
zonal_stats <- resampled_globcover$reduceRegions(
collection = regions,
reducer = ee$Reducer$frequencyHistogram(),  # Histogram for categorical data
scale = 10000,
# Match resampled resolution
)
# Inspect the results
zonal_stats_info <- zonal_stats$getInfo()
africa <- regions$filter(ee$Filter$eq("REGION_NAME", "Africa"))
zonal_stats_africa <- resampled_globcover$reduceRegions(
collection = africa,
reducer = ee$Reducer$frequencyHistogram(),
scale = 10000
)
# Inspect the results
zonal_stats_info <- zonal_stats$getInfo()
# Load IUCN Red List ranges for primates (replace with your dataset)
primates_ranges <- ee$FeatureCollection("IUCN/Ranges/Primates")
# Create smaller sections of the primates ranges by bounding them into rectangles
chunks <- primates_ranges$geometry()$bounds()$buffer(100000)  # 100 km buffer
# Split primate ranges into individual features for processing
chunks <- chunks$toList(chunks$size())  # Convert to a list of geometries
head(primates_ranges)
library(rgee)
ee_Initialize()
# Load IUCN Red List ranges for primates (replace with your dataset)
primates_ranges <- ee$FeatureCollection("IUCN/Ranges/Primates")
# Create smaller sections of the primates ranges by bounding them into rectangles
chunks <- primates_ranges$geometry()$bounds()$buffer(100000)  # 100 km buffer
# Split primate ranges into individual features for processing
chunks <- chunks$toList(chunks$size())  # Convert to a list of geometries
head(primates_ranges)
install.packages("rgee")
rgee::ee_install()
ee_clean_pyenv()
#Next, I need to download the dataset as a GeoTiff file from the ESA GlobCoverLink and use terra to load the data in R
library(terra)
#Next, I need to download the dataset as a GeoTiff file from the ESA GlobCoverLink and use terra to load the data in R
library(terra)
library (landscapemetrics)
#Setup and authenticate rgee to access Google Earth Engine
install.packages("rgee")
library(rgee)
ee_Initialize()
rgee::ee_install()
rgee::ee_install()
