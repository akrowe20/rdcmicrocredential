)
# Compute zonal statistics (percentage of each land cover type per region)
zonal_stats <- resampled_globcover$reduceRegions(
collection = regions,
reducer = ee$Reducer$frequencyHistogram(),  # Histogram for categorical data
scale = 10000  # Match resampled resolution
maxPixels = 1e13
# Resample GlobCover to a coarser resolution (e.g., 10 km)
resampled_globcover <- globcover$reduceResolution(
reducer = ee$Reducer$mode(),  # Use mode for categorical data
maxPixels = 1024
)$reproject(
crs = globcover$projection(),
scale = 10000  # 10 km resolution
)
# Compute zonal statistics (percentage of each land cover type per region)
zonal_stats <- resampled_globcover$reduceRegions(
collection = regions,
reducer = ee$Reducer$frequencyHistogram(),  # Histogram for categorical data
scale = 10000
maxPizels = 1e13# Match resampled resolution
# Compute zonal statistics (percentage of each land cover type per region)
zonal_stats <- resampled_globcover$reduceRegions(
collection = regions,
reducer = ee$Reducer$frequencyHistogram(),  # Histogram for categorical data
scale = 10000
maxPixels = 1e13. # Match resampled resolution
# Compute zonal statistics (percentage of each land cover type per region)
zonal_stats <- resampled_globcover$reduceRegions(
collection = regions,
reducer = ee$Reducer$frequencyHistogram(),  # Histogram for categorical data
scale = 10000
maxPixels = 1e13 # Match resampled resolution
ee_Initialize()
# Load dataset
globcover <- ee$Image("ESA/GLOBCOVER_L4_200901_200912_V2_3")
# Load administrative boundaries (FAO GAUL Level 1)
regions <- ee$FeatureCollection("FAO/GAUL_SIMPLIFIED_500m/2015/level1")
# Resample GlobCover to a coarser resolution (e.g., 10 km)
resampled_globcover <- globcover$reduceResolution(
reducer = ee$Reducer$mode(),  # Use mode for categorical data
maxPixels = 1024
)$reproject(
crs = globcover$projection(),
scale = 10000  # 10 km resolution
)
# Compute zonal statistics (percentage of each land cover type per region)
zonal_stats <- resampled_globcover$reduceRegions(
collection = regions,
reducer = ee$Reducer$frequencyHistogram(),  # Histogram for categorical data
scale = 10000
maxPixels = 1e13 # Match resampled resolution
# Compute zonal statistics (percentage of each land cover type per region)
zonal_stats <- resampled_globcover$reduceRegions(
collection = regions,
reducer = ee$Reducer$frequencyHistogram(),  # Histogram for categorical data
scale = 10000,
maxPixels = 1e13 # Match resampled resolution
)
# Resample GlobCover to a coarser resolution (e.g., 10 km)
resampled_globcover <- globcover$reduceResolution(
reducer = ee$Reducer$mode(),  # Use mode for categorical data
maxPixels = 1024
)$reproject(
crs = globcover$projection(),
scale = 20000  # 10 km resolution
)
# Compute zonal statistics (percentage of each land cover type per region)
zonal_stats <- resampled_globcover$reduceRegions(
collection = regions,
reducer = ee$Reducer$frequencyHistogram(),  # Histogram for categorical data
scale = 10000,
# Match resampled resolution
)
# Inspect the results
zonal_stats_info <- zonal_stats$getInfo()
# Resample GlobCover to a coarser resolution (e.g., 10 km)
resampled_globcover <- globcover$reduceResolution(
reducer = ee$Reducer$mode(),  # Use mode for categorical data
maxPixels = 1024
)$reproject(
crs = globcover$projection(),
scale = 10000  # 10 km resolution
)
# Compute zonal statistics (percentage of each land cover type per region)
zonal_stats <- resampled_globcover$reduceRegions(
collection = regions,
reducer = ee$Reducer$frequencyHistogram(),  # Histogram for categorical data
scale = 10000,
# Match resampled resolution
)
# Inspect the results
zonal_stats_info <- zonal_stats$getInfo()
africa <- regions$filter(ee$Filter$eq("REGION_NAME", "Africa"))
zonal_stats_africa <- resampled_globcover$reduceRegions(
collection = africa,
reducer = ee$Reducer$frequencyHistogram(),
scale = 10000
)
# Inspect the results
zonal_stats_info <- zonal_stats$getInfo()
# Load IUCN Red List ranges for primates (replace with your dataset)
primates_ranges <- ee$FeatureCollection("IUCN/Ranges/Primates")
# Create smaller sections of the primates ranges by bounding them into rectangles
chunks <- primates_ranges$geometry()$bounds()$buffer(100000)  # 100 km buffer
# Split primate ranges into individual features for processing
chunks <- chunks$toList(chunks$size())  # Convert to a list of geometries
head(primates_ranges)
library(rgee)
ee_Initialize()
# Load IUCN Red List ranges for primates (replace with your dataset)
primates_ranges <- ee$FeatureCollection("IUCN/Ranges/Primates")
# Create smaller sections of the primates ranges by bounding them into rectangles
chunks <- primates_ranges$geometry()$bounds()$buffer(100000)  # 100 km buffer
# Split primate ranges into individual features for processing
chunks <- chunks$toList(chunks$size())  # Convert to a list of geometries
head(primates_ranges)
install.packages("rgee")
rgee::ee_install()
ee_clean_pyenv()
#Next, I need to download the dataset as a GeoTiff file from the ESA GlobCoverLink and use terra to load the data in R
library(terra)
#Next, I need to download the dataset as a GeoTiff file from the ESA GlobCoverLink and use terra to load the data in R
library(terra)
library (landscapemetrics)
#Setup and authenticate rgee to access Google Earth Engine
install.packages("rgee")
library(rgee)
ee_Initialize()
rgee::ee_install()
rgee::ee_install()
rgee::ee_check()
rgee::ee_install_upgrade()
rgee::ee_check()
ee_Initialize()
#Load the ESA GlobCover Dataset from the Google Earth Engine
globcover <- ee$Image("ESA/GLOBCOVER_L4_200901_200912_V2_3")
rgee::ee_Initialize()
#Load the ESA GlobCover Dataset from the Google Earth Engine
globcover <- ee$Image("ESA/GLOBCOVER_L4_200901_200912_V2_3")
library(rgee)
#Load the ESA GlobCover Dataset from the Google Earth Engine
globcover <- ee$Image("ESA/GLOBCOVER_L4_200901_200912_V2_3")
#Inspect the dataset
print(globcover)
# Define ROI (Example: Madagascar region)
roi <- ee$Geometry$Rectangle(c(45, -20, 50, -15))
# Resample the dataset to 1 km resolution
resampled_globcover <- globcover$reduceResolution(
reducer = ee$Reducer$mode(),
maxPixels = 1024
)$reproject(
crs = globcover$projection(),
scale = 1000
)
# Calculate land cover percentages
landcover_stats <- resampled_globcover$reduceRegion(
reducer = ee$Reducer$frequencyHistogram(),
geometry = roi,
scale = 1000,
maxPixels = 1e13
)
# Fetch and print results
landcover_percentages <- ee$Dictionary(landcover_stats)$getInfo()
print(landcover_percentages)
#Export results
library(dplyr) # For data manipulation
library(tidyr) # For reshaping data if needed
library(tidyr) # For reshaping data if needed
# Load dataset
globcover <- ee$Image("ESA/GLOBCOVER_L4_200901_200912_V2_3")
# Define ROI (Example: Madagascar region)
roi <- ee$Geometry$Rectangle(c(45, -20, 50, -15))
# Resample the dataset to 1 km resolution
resampled_globcover <- globcover$reduceResolution(
reducer = ee$Reducer$mode(),
maxPixels = 1024
)$reproject(
crs = globcover$projection(),
scale = 1000
)
# Calculate land cover percentages
landcover_stats <- resampled_globcover$reduceRegion(
reducer = ee$Reducer$frequencyHistogram(),
geometry = roi,
scale = 1000,
maxPixels = 1e13
)
# Fetch results
landcover_percentages <- ee$Dictionary(landcover_stats)$getInfo()
# Convert the results into a data frame
landcover_df <- data.frame(
LandCoverClass = names(landcover_percentages),
Frequency = unlist(landcover_percentages)
)
# Optional: Calculate percentage (if total is meaningful)
total <- sum(landcover_df$Frequency)
landcover_df <- landcover_df %>%
mutate(Percentage = (Frequency / total) * 100)
# Export to CSV
write.csv(landcover_df, "landcover_percentages_madagascar.csv", row.names = FALSE)
# Print a success message
print("Land cover percentages exported to landcover_percentages_madagascar.csv")
# Load IUCN Red List ranges for primates (replace with your dataset)
primates_ranges <- ee$FeatureCollection("IUCN/Ranges/Primates")
# Create smaller sections of the primates ranges by bounding them into rectangles
chunks <- primates_ranges$geometry()$bounds()$buffer(100000)  # 100 km buffer
# Split primate ranges into individual features for processing
chunks <- chunks$toList(chunks$size())  # Convert to a list of geometries
# Load dataset
globcover <- ee$Image("ESA/GLOBCOVER_L4_200901_200912_V2_3")
# Define ROI (Example: Madagascar region)
roi <- ee$Geometry$Rectangle(c(45, -20, 50, -15))
# Select the 'landcover' band explicitly
landcover_band <- globcover$select("landcover")
# Resample the dataset to 1 km resolution
resampled_globcover <- landcover_band$reduceResolution(
reducer = ee$Reducer$mode(),
maxPixels = 1024
)$reproject(
crs = landcover_band$projection(),
scale = 1000
)
# Calculate land cover percentages
landcover_stats <- resampled_globcover$reduceRegion(
reducer = ee$Reducer$frequencyHistogram(),
geometry = roi,
scale = 1000,
maxPixels = 1e13
)
# Fetch results
landcover_percentages <- ee$Dictionary(landcover_stats)$getInfo()
# Fetch results
landcover_percentages <- ee$Dictionary(landcover_stats)$getInfo()
# Convert the results into a data frame
landcover_df <- data.frame(
LandCoverClass = names(landcover_percentages),
Frequency = unlist(landcover_percentages)
)
# Optional: Calculate percentage
total <- sum(landcover_df$Frequency)
landcover_df <- landcover_df %>%
mutate(Percentage = (Frequency / total) * 100)
# Export to CSV
write.csv(landcover_df, "landcover_percentages_madagascar.csv", row.names = FALSE)
# Print a success message
print("Land cover percentages exported to landcover_percentages_madagascar.csv")
print(globcover$bandNames()$getInfo())
Map$setCenter(47.5, -18, 6) # Center the map on Madagascar
Map$addLayer(roi, {}, "ROI")
Map$addLayer(roi, {}, "ROI")
Map$addLayer(globcover, {}, "Globcover")
print(landcover_stats$getInfo())
print(globcover$bandNames()$getInfo())
# Load dataset
globcover <- ee$Image("ESA/GLOBCOVER_L4_200901_200912_V2_3")
# Verify band names
print(globcover$bandNames()$getInfo())
# Define ROI (Madagascar region)
roi <- ee$Geometry$Rectangle(c(45, -20, 50, -15))
# Select the 'landcover' band (verify the name matches output from print above)
landcover_band <- globcover$select("landcover")
# Resample the dataset to 1 km resolution
resampled_globcover <- landcover_band$reduceResolution(
reducer = ee$Reducer$mode(),
maxPixels = 1024
)$reproject(
crs = landcover_band$projection(),
scale = 1000
)
# Calculate land cover percentages
landcover_stats <- resampled_globcover$reduceRegion(
reducer = ee$Reducer$frequencyHistogram(),
geometry = roi,
scale = 1000,
maxPixels = 1e13
)
# Debug: Check the reduceRegion output
print(landcover_stats$getInfo())
# Fetch results and convert to data frame
landcover_percentages <- ee$Dictionary(landcover_stats)$getInfo()
if (!is.null(landcover_percentages)) {
landcover_df <- data.frame(
LandCoverClass = names(landcover_percentages),
Frequency = unlist(landcover_percentages)
)
# Optional: Calculate percentage
total <- sum(landcover_df$Frequency)
landcover_df <- landcover_df %>%
mutate(Percentage = (Frequency / total) * 100)
# Export to CSV
write.csv(landcover_df, "landcover_percentages_madagascar.csv", row.names = FALSE)
print("Land cover percentages exported to landcover_percentages_madagascar.csv")
} else {
print("No data was retrieved. Check ROI and dataset alignment.")
}
# Convert the results into a data frame
landcover_percentages <- ee$Dictionary(landcover_stats)$getInfo()
# Load dataset
globcover <- ee$Image("ESA/GLOBCOVER_L4_200901_200912_V2_3")
# Verify band names
print(globcover$bandNames()$getInfo())
# Define ROI (Madagascar region)
roi <- ee$Geometry$Rectangle(c(45, -20, 50, -15))
# Select the 'landcover' band (verify the name matches output from print above)
landcover_band <- globcover$select("landcover")
# Resample the dataset to 1 km resolution
resampled_globcover <- landcover_band$reduceResolution(
reducer = ee$Reducer$mode(),
maxPixels = 1024
)$reproject(
crs = landcover_band$projection(),
scale = 1000
)
# Calculate land cover percentages
landcover_stats <- resampled_globcover$reduceRegion(
reducer = ee$Reducer$frequencyHistogram(),
geometry = roi,
scale = 1000,
maxPixels = 1e13
)
# Debug: Check the reduceRegion output
print(landcover_stats$getInfo())
# Convert the results into a data frame
landcover_percentages <- ee$Dictionary(landcover_stats)$getInfo()
if (!is.null(landcover_percentages)) {
# Create the data frame explicitly
landcover_df <- data.frame(
LandCoverClass = names(landcover_percentages), # Extract keys
Frequency = as.numeric(unlist(landcover_percentages)) # Extract values and convert to numeric
)
# Optional: Calculate percentage
total <- sum(landcover_df$Frequency, na.rm = TRUE) # Avoid errors from NA values
landcover_df <- landcover_df %>%
mutate(Percentage = (Frequency / total) * 100)
# Debug: Print the data frame to check structure before exporting
print(landcover_df)
# Export to CSV
write.csv(landcover_df, "landcover_percentages_madagascar.csv", row.names = FALSE)
print("Land cover percentages exported to landcover_percentages_madagascar.csv")
} else {
print("No data retrieved. Check ROI and dataset alignment.")
}
print(landcover_percentages)
# Load the Globcover dataset
globcover <- ee$Image("ESA/GLOBCOVER_L4_200901_200912_V2_3")
# Define ROI (Madagascar region)
roi <- ee$Geometry$Rectangle(c(45, -20, 50, -15))
# Select the 'landcover' band explicitly
landcover_band <- globcover$select("landcover")
# Clip the image to the ROI
landcover_clipped <- landcover_band$clip(roi)
# Export the landcover image as a GeoTIFF to your Google Drive
task <- ee$batch$Export$image.toDrive(
image = landcover_clipped,
description = "LandCover_Madagascar",
folder = "EarthEngineExports", # Change this to your desired folder
fileNamePrefix = "landcover_madagascar",
scale = 1000, # Pixel resolution
region = roi$bounds(),
crs = "EPSG:4326", # Coordinate reference system
maxPixels = 1e13
)
# Load the Globcover dataset
globcover <- ee$Image("ESA/GLOBCOVER_L4_200901_200912_V2_3")
globcover = rast(globcover)
# Load the Globcover dataset
library(terra)
library(dplyr)
globcover <- ee$Image("ESA/GLOBCOVER_L4_200901_200912_V2_3")
globcover = rast(globcover)
var globcover = ee.Image("ESA/GLOBCOVER_L4_200901_200912_V2_3");
#Initialize the GEE Image
var globcover = ee.Image("ESA/GLOBCOVER_L4_200901_200912_V2_3");
library(sf)
# Step 1: Initialize rgee and authenticate
ee_Initialize()
# Step 2: Load the ESA Globcover image
globcover <- ee$Image("ESA/GLOBCOVER_L4_200901_200912_V2_3")
# Step 3: Define an area of interest (global extent or specific region)
aoi <- ee$Geometry$Rectangle(-180, -90, 180, 90) # Global extent
# Step 4: Export the image to Google Drive
task <- ee_image_to_drive(
image = globcover$clip(aoi),
description = "ESA_Globcover",
scale = 300,  # Native resolution (300m)
region = aoi,
fileFormat = "GeoTIFF",
maxPixels = 1e13
)
# Start the export task
task$start()
print("Export started. Check your Google Drive for the file.")
# Optional: Monitor the task
ee_monitoring(task)
library(terra)
# Load the raster
r <- rast("input.tif")
# Load the raster
r <- rast("GlobCover_2009_Global-0000000000-0000000000.tif")
# Load the raster
r <- rast("GlobCover_2009_Global-0000000000-0000000000.tif")
setwd("~/Dropbox/CU Postdoc/Resources, Workshops, Tutorials/Data Foundations Camp/FinalProject/GitHub/rdcmicrocredential/Data")
# Load the raster
r <- rast("GlobCover_2009_Global-0000000000-0000000000.tif")
# Define the aggregation factor (e.g., 10x10)
agg_factor <- 10
# Aggregate raster (mean for continuous data, majority for categorical)
r_agg <- aggregate(r, fact = agg_factor, fun = "modal") # For land cover types
# Save the aggregated raster (optional)
writeRaster(r_agg, "rescaled_raster.tif", overwrite = TRUE)
# Aggregate with "modal" function (for categorical land cover types)
r_agg <- aggregate(r, fact = agg_factor, fun = "modal")  # Can use "mean" for continuous data
# Aggregate with "modal" function (for categorical land cover types)
r_agg <- aggregate(r, fact = agg_factor, fun = "modal")  # Can use "mean" for continuous data
# Plot to confirm the aggregation
plot(r_agg, main = "Rescaled Raster")
# Create a grid from the aggregated raster
grid <- as.polygons(r_agg)
grid$cell_id <- 1:nrow(grid)  # Assign unique IDs to cells
# Use the original raster for finer details
zones <- zonal(r, grid, fun = "frequency", na.rm = TRUE)
library(dplyr)
# Use the original raster for finer details
zones <- zonal(r, grid, fun = "frequency", na.rm = TRUE)
# Use the original raster for finer details
zones <- terra::zonal(r, grid, fun = "frequency", na.rm = TRUE)
# Extract land cover types within each grid cell
values <- extract(r, grid)
# Calculate the percentage of each land cover type per cell
percentages <- values %>%
group_by(ID, value) %>%  # Group by cell ID and land cover type
summarise(count = n(), .groups = "drop") %>%
group_by(ID) %>%  # For each cell
mutate(percentage = 100 * count / sum(count)) %>%
ungroup()
library(terra)
# Use the original raster for finer details
zones <- zonal(r, grid, fun = "frequency", na.rm = TRUE)
?zonal
# Calculate percentage per cell
zones <- zones %>%
group_by(cell_id) %>%
mutate(percentage = 100 * value / sum(value)) %>%
ungroup()
values <- extract(r, grid)
percentages <- values %>%
group_by(ID, value) %>%  # Group by cell ID and land cover type
summarise(count = n(), .groups = "drop") %>%
group_by(ID) %>%  # For each cell
mutate(percentage = 100 * count / sum(count)) %>%
ungroup()
plot(grid, main = "Grid from Aggregated Raster")
values <- extract(r, grid)
head(values)
str(values)
colnames(values)[colnames(values) != "ID"] <- "value"  # Ensure pixel values are in a column named 'value'
percentages <- values %>%
group_by(ID, value) %>%  # Group by cell ID and land cover type
summarise(count = n(), .groups = "drop") %>%
group_by(ID) %>%  # For each cell
mutate(percentage = 100 * count / sum(count)) %>%
ungroup()
# Calculate the percentage of each land cover type per cell
percentages <- values %>%
group_by(ID, value) %>%  # Group by cell ID and land cover type
summarise(count = n(), .groups = "drop") %>%  # Count pixels for each type
group_by(ID) %>%  # Group by cell ID
mutate(percentage = 100 * count / sum(count)) %>%  # Calculate percentage
ungroup()
values <- extract(r, grid)
str(values)
colnames(values)
colnames(values)[colnames(values) != "ID"] <- "value"
# Calculate the percentage of each land cover type per cell
percentages <- values %>%
group_by(ID, value) %>%  # Group by cell ID and land cover type
summarise(count = n(), .groups = "drop") %>%  # Count pixels for each type
group_by(ID) %>%  # Group by cell ID
mutate(percentage = 100 * count / sum(count)) %>%  # Calculate percentage
ungroup()
# Calculate the percentage of each land cover type per cell
percentages <- values %>%
group_by(ID, values) %>%  # Group by cell ID and land cover type
summarise(count = n(), .groups = "drop") %>%  # Count pixels for each type
group_by(ID) %>%  # Group by cell ID
mutate(percentage = 100 * count / sum(count)) %>%  # Calculate percentage
ungroup()
# Load the raster
r <- rast("GlobCover_2009_Global-0000000000-0000000000.tif")
# Define the aggregation factor (e.g., 10x10)
agg_factor <- 10
# Aggregate with "modal" function (for categorical land cover types)
r_agg <- aggregate(r, fact = agg_factor, fun = "modal")  # Can use "mean" for continuous data
# Create a grid from the aggregated raster
grid <- as.polygons(r_agg)
grid$cell_id <- 1:nrow(grid)  # Assign unique IDs to cells
values <- extract(r, grid)
# Rename columns to avoid duplicates
colnames(values) <- make.names(colnames(values), unique = TRUE)
# Ensure the column with pixel values is named "value"
if (!"value" %in% colnames(values)) {
value_col <- colnames(values)[!colnames(values) %in% c("ID")]
colnames(values)[colnames(values) == value_col] <- "value"
}
# Calculate the percentage of each land cover type per cell
percentages <- values %>%
group_by(ID, value) %>%                # Group by grid cell ID and land cover type
summarise(count = n(), .groups = "drop") %>%  # Count pixels for each land cover type
group_by(ID) %>%                       # Group by grid cell ID
mutate(percentage = 100 * count / sum(count)) %>%  # Calculate percentages
ungroup()
